{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_implementation_of_tf_idf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakher2pratyush/tf_idf/blob/main/custom_implementation_of_tf_idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What does TF-IDF mean?\n",
        "TF-IDF stands for term frequency-inverse document frequency, and it means converting a data corpus into a sparse matrix using frequency of a word in a document (TF) along with log of inverse of frequency of documents that contains the word in data corpus (IDF)"
      ],
      "metadata": {
        "id": "0-8_83mIjENN"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUsYm9wjxLi1"
      },
      "source": [
        "corpus = [\n",
        "     'this is the first document',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEXx09hjimjV",
        "outputId": "376eebff-cfd7-4eda-e105-eeb77aae7ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLwmFZfKxLi4"
      },
      "source": [
        "### SkLearn Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np4dfQOkxLi4"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(corpus)\n",
        "skl_output = vectorizer.transform(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Om8YpYxLi6",
        "outputId": "0a3bd0f5-4424-4400-944f-4482a80bd799"
      },
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTKplK96xLi-",
        "outputId": "53722fa2-6756-4aa0-f179-37b578bb6890"
      },
      "source": [
        "print(vectorizer.idf_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
            " 1.         1.91629073 1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CTiWHygxLjA",
        "outputId": "8d5a9cde-2c29-4afe-f7b4-1547e88dba4f"
      },
      "source": [
        "skl_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDKEpbA-xLjD",
        "outputId": "87dafd65-5313-443f-8c6e-1b05cc8c2543"
      },
      "source": [
        "print(skl_output[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 8)\t0.38408524091481483\n",
            "  (0, 6)\t0.38408524091481483\n",
            "  (0, 3)\t0.38408524091481483\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 1)\t0.46979138557992045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QWo34hexLjF",
        "outputId": "cdc04e08-989f-4bdc-dd7f-f1c82a9f90be"
      },
      "source": [
        "print(skl_output[0].toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfIwx5LzxLjI"
      },
      "source": [
        "### Custom Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjuCcJwXxLjJ"
      },
      "source": [
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "import operator\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy\n",
        "\n",
        "# fit function\n",
        "\n",
        "def fit(dataset):    \n",
        "\n",
        "  if isinstance(dataset, (list,)):\n",
        "\n",
        "    # To get the vocabulary\n",
        "    vocabulary = [];\n",
        "    for sentance in dataset:\n",
        "      for word in sentance.split(\" \"):\n",
        "        if len(word) < 2:\n",
        "          continue\n",
        "        if word not in vocabulary:\n",
        "          vocabulary.append(word)           # If word not exist in Vocabulary, add.\n",
        "    vocabulary = sorted(list(vocabulary))   # Sort the vocabulary.\n",
        "    \n",
        "    # To get the IDF\n",
        "    total_documents = len(dataset)\n",
        "    idf = []\n",
        "    for word in vocabulary:\n",
        "      sum_idf = 0\n",
        "      for sentance in dataset:\n",
        "        if word in sentance:\n",
        "          sum_idf += 1  \n",
        "      idf_word = 1 + math.log((1 + total_documents)/(1 + sum_idf))\n",
        "      idf.append(idf_word)\n",
        "\n",
        "    return vocabulary, idf\n",
        "\n",
        "  else:\n",
        "        print(\"Kindly pass list of strings\")\n",
        "        \n",
        "feature_names, idf_ = fit(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKZbq_bDrEZh",
        "outputId": "acc1490b-fc14-4b6b-f1bc-e7af8a0ada80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(idf_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSBxyxA_rGaI",
        "outputId": "debd341d-0dec-4aa4-f958-8db4106f40c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform function\n",
        "\n",
        "def transform(dataset,vocab,idf):\n",
        "    rows = []\n",
        "    columns = []\n",
        "    values = []\n",
        "    if isinstance(dataset, (list,)):\n",
        "        for idx, row in enumerate(tqdm(dataset)): \n",
        "            word_freq = dict(Counter(row.split()))\n",
        "            for word, freq in word_freq.items():               \n",
        "                if len(word) < 2:\n",
        "                    continue\n",
        "\n",
        "                # Get the Term Frequency\n",
        "                tf_word = freq/len(row)\n",
        "\n",
        "                # Get the IDF\n",
        "                vocab_index = vocab.index(word)\n",
        "                idf_word = idf[vocab_index]\n",
        "\n",
        "                # Get the TF-IDF\n",
        "                tfidf = tf_word*idf_word\n",
        "\n",
        "                col_index = vocab_index \n",
        "                if col_index !=-1:\n",
        "                    rows.append(idx)\n",
        "                    columns.append(col_index)\n",
        "                    values.append(tfidf)\n",
        "        return normalize(csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocab))))\n",
        "    else:\n",
        "        print(\"Kindly pass list of strings\")\n",
        "\n",
        "output_transform = transform(corpus, feature_names, idf_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH2mOfG0tgoH",
        "outputId": "27f201cb-a41f-4de0-f67e-6c20b6d4c362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 2362.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_transform.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9bncsjbxBYj",
        "outputId": "6166cb97-da28-4f86-a8d1-78770703560b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_transform[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta045UNSxIZh",
        "outputId": "5e9ba204-7622-4d83-eea8-ebad86eba3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 1)\t0.46979138557992045\n",
            "  (0, 2)\t0.5802858236844359\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_transform[0].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMfJNgzExXwH",
        "outputId": "eb43ae23-57cd-4d9b-bf4d-2cea5ffeca99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMxBmVZExLjK"
      },
      "source": [
        "## Modified TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51j_OtqAxLjL"
      },
      "source": [
        "### Implement max features functionality\n",
        "\n",
        "Modified TF-IDF such that vocab will contain only 50 terms with top idf scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHxPLlwNxLjL",
        "outputId": "bdbd0dec-4557-42b8-cd5c-863448235675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pickle\n",
        "\n",
        "# Python pickle module is used for serializing and de-serializing a Python object structure. \n",
        "# Any object in Python can be pickled so that it can be saved on disk. \n",
        "# Pickling is a way to convert a python object (list, dict, etc.) into a character stream.\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Data/cleaned_strings', 'rb') as f:\n",
        "    corpus = pickle.load(f)\n",
        "    \n",
        "# printing the length of the corpus loaded\n",
        "print(\"Number of documents in corpus = \",len(corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in corpus =  746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_DJnnR3xLjR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bee93861-83ef-40db-c03a-a338d668717d"
      },
      "source": [
        "def updated_fit(dataset):    \n",
        "\n",
        "  if isinstance(dataset, (list,)):\n",
        "\n",
        "    # To get the vocabulary\n",
        "    vocabulary = [];\n",
        "    for sentance in dataset:\n",
        "      for word in sentance.split(\" \"):\n",
        "        if len(word) < 2:\n",
        "          continue\n",
        "        if word not in vocabulary:\n",
        "          vocabulary.append(word)           # If word not exist in Vocabulary, add.\n",
        "    vocabulary = sorted(list(vocabulary))   # Sort the vocabulary.\n",
        "    \n",
        "    # To get the IDF\n",
        "    total_documents = len(dataset)\n",
        "    idf = []\n",
        "    for word in vocabulary:\n",
        "      sum_idf = 0\n",
        "      for sentance in dataset:\n",
        "        if word in sentance:\n",
        "          sum_idf += 1  \n",
        "      idf_word = 1 + math.log((1 + total_documents)/(1 + sum_idf))\n",
        "      idf.append(idf_word)\n",
        "    \n",
        "    updated_vocab = []\n",
        "    updated_idf = []\n",
        "\n",
        "    for i in range(0,50):\n",
        "      idx = idf.index(max(idf))\n",
        "      updated_idf.append(idf[idx])\n",
        "      updated_vocab.append(vocabulary[idx])\n",
        "      idf.pop(idx)\n",
        "      vocabulary.pop(idx)\n",
        "      i += 1\n",
        "\n",
        "    return updated_vocab, updated_idf\n",
        "\n",
        "  else:\n",
        "        print(\"Kindly pass list of strings\")\n",
        "        \n",
        "updated_feature_names, updated_idf_ = updated_fit(corpus)\n",
        "\n",
        "def updated_transform(dataset,vocab,idf):\n",
        "    rows = []\n",
        "    columns = []\n",
        "    values = []\n",
        "    if isinstance(dataset, (list,)):\n",
        "        for idx, row in enumerate(tqdm(dataset)): \n",
        "            word_freq = dict(Counter(row.split()))\n",
        "            for word, freq in word_freq.items():  \n",
        "                # Additional condition to remove words which are not in Vocab             \n",
        "                if len(word) < 2 or word not in vocab:\n",
        "                    continue\n",
        "\n",
        "                # Get the Term Frequency\n",
        "                tf_word = freq/len(row)\n",
        "\n",
        "                # Get the IDF\n",
        "                vocab_index = vocab.index(word)\n",
        "                idf_word = idf[vocab_index]\n",
        "\n",
        "                # Get the TF-IDF\n",
        "                tfidf = tf_word*idf_word\n",
        "\n",
        "                col_index = vocab_index \n",
        "                if col_index !=-1:\n",
        "                    rows.append(idx)\n",
        "                    columns.append(col_index)\n",
        "                    values.append(tfidf)\n",
        "        return normalize(csr_matrix((values, (rows,columns)), shape=(len(dataset),len(vocab))))\n",
        "    else:\n",
        "        print(\"Kindly pass list of strings\")\n",
        "\n",
        "updated_output_transform = updated_transform(corpus, updated_feature_names, updated_idf_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 746/746 [00:00<00:00, 33699.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Size of Vocabulary : \" + str(len(updated_feature_names)))\n",
        "print(\"Size of IDF : \" + str(len(updated_idf_)))\n",
        "print(\"\\n\")\n",
        "print(\"IDF\\t\\t\\t:\\tWord\")\n",
        "for i in range(0,50):\n",
        "  print(str(updated_idf_[i]) + \"\\t:\\t\" + updated_feature_names[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQVujXVk6etX",
        "outputId": "fcd60423-679a-4e9b-d934-0d3600017385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Vocabulary : 50\n",
            "Size of IDF : 50\n",
            "\n",
            "\n",
            "IDF\t\t\t:\tWord\n",
            "6.922918004572872\t:\taailiyah\n",
            "6.922918004572872\t:\tabandoned\n",
            "6.922918004572872\t:\tabroad\n",
            "6.922918004572872\t:\tabstruse\n",
            "6.922918004572872\t:\tacademy\n",
            "6.922918004572872\t:\taccents\n",
            "6.922918004572872\t:\taccessible\n",
            "6.922918004572872\t:\tacclaimed\n",
            "6.922918004572872\t:\taccolades\n",
            "6.922918004572872\t:\taccurately\n",
            "6.922918004572872\t:\tachille\n",
            "6.922918004572872\t:\tackerman\n",
            "6.922918004572872\t:\tadams\n",
            "6.922918004572872\t:\tadded\n",
            "6.922918004572872\t:\tadmins\n",
            "6.922918004572872\t:\tadmiration\n",
            "6.922918004572872\t:\tadmitted\n",
            "6.922918004572872\t:\tadrift\n",
            "6.922918004572872\t:\tadventure\n",
            "6.922918004572872\t:\taesthetically\n",
            "6.922918004572872\t:\taffected\n",
            "6.922918004572872\t:\taffleck\n",
            "6.922918004572872\t:\tafternoon\n",
            "6.922918004572872\t:\tagreed\n",
            "6.922918004572872\t:\taimless\n",
            "6.922918004572872\t:\taired\n",
            "6.922918004572872\t:\takasha\n",
            "6.922918004572872\t:\talert\n",
            "6.922918004572872\t:\talike\n",
            "6.922918004572872\t:\tallison\n",
            "6.922918004572872\t:\tallowing\n",
            "6.922918004572872\t:\talongside\n",
            "6.922918004572872\t:\tamateurish\n",
            "6.922918004572872\t:\tamazed\n",
            "6.922918004572872\t:\tamazingly\n",
            "6.922918004572872\t:\tamusing\n",
            "6.922918004572872\t:\tamust\n",
            "6.922918004572872\t:\tanatomist\n",
            "6.922918004572872\t:\tangela\n",
            "6.922918004572872\t:\tangelina\n",
            "6.922918004572872\t:\tangry\n",
            "6.922918004572872\t:\tanguish\n",
            "6.922918004572872\t:\tangus\n",
            "6.922918004572872\t:\tanimals\n",
            "6.922918004572872\t:\tanimated\n",
            "6.922918004572872\t:\tanita\n",
            "6.922918004572872\t:\tanniversary\n",
            "6.922918004572872\t:\tanthony\n",
            "6.922918004572872\t:\tantithesis\n",
            "6.922918004572872\t:\tanyway\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_output_transform.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2lwAUu07RXE",
        "outputId": "8874178f-ef05-4bd9-ab45-b5fe3530550b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(746, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(updated_output_transform[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM9caIdJ8CX0",
        "outputId": "e679584e-93ce-4dd1-b390-d169cc6f7af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 24)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(updated_output_transform[0].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_P-rrEx8MC_",
        "outputId": "57cdc3c6-3a1e-4f78-e6f7-479799d2600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0.]]\n"
          ]
        }
      ]
    }
  ]
}